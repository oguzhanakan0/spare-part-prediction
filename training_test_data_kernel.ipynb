{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# README #\n",
    "\n",
    "Bu dosyada data_preparation.ipynb'den çıkan raw_training_data.csv'yi finalize ederek train ve test olarak ikiye bölüyoruz.\n",
    "\n",
    "- 2013-2014 datasını tablodan çıkarıyoruz çünkü birçok 'time-series' feature'u kullandık ve 2013-2014'te bu değerlerin çoğu boş geliyor.\n",
    "- Raw data'daki takım ismi, hakem ismi gibi kolonları çıkarttık. Elimizde sadece modelde kullanacağımız feature'lar ve TARGET alanı kaldı\n",
    "- Null Treatment yaptık:\n",
    "    - Null treatment'ta, her bir kolon için, o kolonun ortalamasını ve standart sapmasını hesapladık. Sonra her bir boş hücreye ortalama +- standart sapma aralığından rastgele bir değer seçerek o değeri atadık. Böylece randomizasyonu sağlamış ve mantıksız değerler üretmemiş olduk.\n",
    "    - Sonuç olarak, elimize her hücresi dolu bir data geçti.\n",
    "- Modellemeye geçmeden önceki son adım train ve test datası olarak iki data oluşturmak. Modeli train'i kullanarak kuracağız ve test'i kullanarak hiç görmediğimiz bir datayı tahmin edip doğru tahmin ettik mi diye bakacağız.\n",
    "    - train_test_split(raw,test_size=0.2,random_state=17) fonksiyonunu kullanarak raw datayı %80'i train %20'si test olacak şekilde ayırdık ve training_test_data klasöründe train.csv ve test.csv olarak iki dosyaya yazdık.\n",
    "    \n",
    "Buraya kadar okuduysanız model_selection.ipynb dosyasına geçebilirsiniz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We read the raw training data extracted from data_preparation.ipynb\n",
    "raw = pd.read_csv('./raw_training_data/raw_training_data.csv')\n",
    "cols = list(raw.columns)\n",
    "# We reduce the columns to only ones that we will use for modeling, e.g. we do not need to include the teams' names in training data.\n",
    "cols = cols[cols.index('TARGET'):]\n",
    "raw = raw[cols]\n",
    "# Since we will use a lot of time-series features, we needed to delete the first season of the data as a lot of the columns are NULL.\n",
    "raw = raw[raw.Season>20132014]\n",
    "# At the end, we are only left with TARGET column and the set of features we will use for our modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# More features defined here..\n",
    "raw['MKT_VAL_RATIO']=raw.HOME_MKT_VAL/raw.AWAY_MKT_VAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Null treatment - We produce random numbers that are obtained from a uniform distribution that has a range of mean +- standard deviation of that specific column\n",
    "pd.options.mode.chained_assignment = None\n",
    "def null_treat(df, col):\n",
    "    avg = df[col].mean()\n",
    "    std = df[col].std()\n",
    "    null_count = df[col].isnull().sum()\n",
    "    null_random_list = np.random.uniform(avg - std, avg + std, size=null_count)\n",
    "    df[col][np.isnan(df[col])] = null_random_list\n",
    "    return df[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feat in [e for e in raw if e!='TARGET']:\n",
    "    raw[feat]=null_treat(raw,feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.drop('Season',inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitted = train_test_split(raw,test_size=0.2,random_state=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.DataFrame(splitted[0])\n",
    "test = pd.DataFrame(splitted[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train target mean: 1.852796052631579\n",
      "Test target mean: 1.7960526315789473\n"
     ]
    }
   ],
   "source": [
    "print('Train target mean: '+str(train['TARGET'].mean()))\n",
    "print('Test target mean: '+ str(test['TARGET'].mean()))\n",
    "# We made sure that the data is stratified when splitting into train and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('./training_test_data/train.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv('./training_test_data/test.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
